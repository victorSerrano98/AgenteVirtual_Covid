{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraficaAjuste.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUwPe39SB_Rp",
        "outputId": "5dbfed68-b2f3-47c1-fdb7-e4a5da3a7490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0\n",
            "  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 68.7 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 35.7 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 25.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.21.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Installing collected packages: torch, torchvision, torchtext, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "Successfully installed torch-1.9.0 torchaudio-0.9.0 torchtext-0.10.0 torchvision-0.10.0\n",
            "Collecting transformers==4.8.0\n",
            "  Downloading transformers-4.8.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.11.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (3.13)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (1.21.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.8.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.8.0) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.8.0) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.49 tokenizers-0.10.3 transformers-4.8.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 12.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 torchtext==0.10.0\n",
        "#!pip uninstall transformers -y\n",
        "!pip install transformers==4.8.0\n",
        "!pip install transformers sentencepiece\n",
        "!pip install tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ3lrB9WBbJ-",
        "outputId": "36131385-2fa1-40f4-e256-61721155c144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch, time, gc\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCYepNomOQxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dbf140-6310-4842-c3a0-53267f08cfc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 24 15:43:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    29W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGCFFRKMHui2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4e004e-9883-411f-d4ed-77081bec9ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiFVXS-NECVR"
      },
      "outputs": [],
      "source": [
        "def read_squad(path):\n",
        "    # se abre el archivo JSON y cargue el diccionario de introducción\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "    # inicializar listas para contextos, preguntas y respuestas // título, pregunta, respuesta, resumen (contextos)\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    # itera a través de todos los datos \n",
        "\n",
        "    for i in squad_dict:\n",
        "        try:\n",
        "            context = i['context']\n",
        "            question = i['question']\n",
        "            answer = i['answer']\n",
        "            # comprueba si necesitamos extraer de 'answers' o 'plausible_answers'\n",
        "            if 'plausible_answers' in i.keys():\n",
        "                access = 'plausible_answers'\n",
        "            else:\n",
        "                access = 'answers'\n",
        "            # agregar datos a listas // título, pregunta, respuesta, resumen\n",
        "            contexts.append(context)\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "        except:\n",
        "            print(\"eeee\")\n",
        "    # devolver listas de datos \n",
        "    return contexts, questions, answers\n",
        "\n",
        "# se ejecuta la función de lectura SQuAD para conjuntos de entrenamiento y validación\n",
        "train_contexts, train_questions, train_answers = read_squad('/content/drive/MyDrive/ajusteBert/datosunido.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('/content/drive/MyDrive/ajusteBert/datosCopy.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVxASePjEI8r"
      },
      "outputs": [],
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    # se recorre cada par respuesta-contexto\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        # gold_text se refiere a la respuesta que esperamos encontrar en contexto\n",
        "        print(answer['text'])\n",
        "        gold_text = answer['text']\n",
        "        # se conoce el índice de inicio\n",
        "        start_idx = answer['answer_start']\n",
        "        # idealmente este sería el índice final\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # A veces las respuestas se desvían por un personaje o dos\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            # si la respuesta no es apagada\n",
        "            answer['answer_end'] = end_idx\n",
        "        else:\n",
        "            # esto significa que la respuesta está desviada por 1-2 tokens\n",
        "            for n in [1, 2]:\n",
        "                if context[start_idx - n:end_idx - n] == gold_text:\n",
        "                    answer['answer_start'] = start_idx - n\n",
        "                    answer['answer_end'] = end_idx - n\n",
        "\n",
        "# y se aplica la función a nuestras dos listas de respuestas\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iVwfDJ1D47m"
      },
      "outputs": [],
      "source": [
        "print(train_answers[:5])\n",
        "from transformers import AutoTokenizer\n",
        "# inicializar el tokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
        "# tokenizador\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
        "print(tokenizer.decode(train_encodings['input_ids'][0]))\n",
        "\n",
        "def add_token_positions(encodings, answers):\n",
        "    # se inicializa las listas para contener los índices de token de inicio / final de respuesta\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i in range(len(answers)):\n",
        "        print(answers[i]['answer_start'])\n",
        "        print(answers[i]['text'])\n",
        "        # agregar la posición del token de inicio / finalización usando el método char_to_token\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
        "        # si la posición inicial es None, el pasaje de respuesta se ha truncado\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        # la posición final no se puede encontrar, char_to_token encontró el espacio, así que cambie la posición hasta encontrarla\n",
        "        shift = 1\n",
        "        while end_positions[-1] is None:\n",
        "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n",
        "            shift += 1\n",
        "    # Actualiza nuestro objeto de codificaciones con las nuevas posiciones de inicio / finalización basadas en tokens.\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "# Se aplica la funcion a los datos\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffEdF97DEwLy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKFhRbkHDYUa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline, QuestionAnsweringPipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering\n",
        "model_path = \"JAlexis/PruebaBert\"\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "y6vFETkctGSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f3104c-9f4c-4440-dee7-7658b00a0f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_loader(batch_size=7,dump_equals=False):\n",
        "    dump_equals=False\n",
        "    model.eval()\n",
        "    acc = []\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    dump_count = 0\n",
        "    eval_data = []\n",
        "    for batch in train_loader:\n",
        "        with torch.no_grad():\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            start_true = batch['start_positions'].to(device)\n",
        "            end_true = batch['end_positions'].to(device)\n",
        "            # realiza estimaciones\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            # obtien la mejor predicción con argmax\n",
        "            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "            # calcula la precisión \n",
        "            acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "            acc.append(((end_pred == end_true).sum()/len(end_pred)).item())     \n",
        "            \n",
        "            eval_data.append([start_pred , start_true,end_pred , end_true])\n",
        "\n",
        "            if dump_equals and dump_count < 14 and start_pred == start_true and end_pred == end_true:\n",
        "              dump_count += 1\n",
        "              tokens = tokenizer.convert_ids_to_tokens(batch['input_ids'][0])\n",
        "              pred = get_text_atrange(  tokens,start_pred[0],end_pred[0] )\n",
        "              print(\"tokens\",pred )\n",
        "              print(\"start_pred == start_true\",start_pred , start_true)\n",
        "              print(\"end_pred == end_true\",end_pred , end_true)\n",
        "              print(\"--\") \n",
        "    # calcula de la precisión total, promediando las precisiones\n",
        "    acc = sum(acc)/len(acc)\n",
        "    print(\"Precisión del modelo ajustado:\", acc)\n",
        "    print(\"eval_data\", eval_data)\n",
        "    return acc ,eval_data\n",
        "\n"
      ],
      "metadata": {
        "id": "CtuC1AJRuTeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_eval(eval_data):\n",
        "  fig, axes = plt.subplots(3,1)\n",
        "  fig.set_size_inches(11, 8)\n",
        "  axes[0].set_title(\"Predicción\")\n",
        "  axes[1].set_title(\"Real\")\n",
        "  axes[2].set_title(\"Combinado\")\n",
        "  for index,e_data in enumerate(eval_data):\n",
        "    start_pred , end_pred =  e_data[0] , e_data[2]\n",
        "    start_true , end_true =  e_data[1] , e_data[3]\n",
        "    \n",
        "    if abs(start_true - end_true) < 100:\n",
        "      axes[0].plot([index,index],[start_pred.cpu().numpy(), end_pred.cpu().numpy()],color=\"blue\",linestyle='-')\n",
        "      axes[1].plot([index,index],[start_true.cpu().numpy(), end_true.cpu().numpy()],color=\"orange\")  \n",
        "\n",
        "      axes[2].plot([index*2,index*2],[start_pred.cpu().numpy(), end_pred.cpu().numpy()],color=\"blue\",linestyle='-')\n",
        "      axes[2].plot([index*2+1,index*2+1],[start_true.cpu().numpy(), end_true.cpu().numpy()],color=\"orange\")  \n",
        "      \n",
        "  fig.tight_layout()"
      ],
      "metadata": {
        "id": "WLcxaZZWtipO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc,eval_data = eval_loader(1,dump_equals=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F9zmZusuHtZ",
        "outputId": "6ebe56d5-1967-4325-8e43-74b5da817313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo ajustado: 0.964\n",
            "eval_data [[tensor([44], device='cuda:0'), tensor([44], device='cuda:0'), tensor([47], device='cuda:0'), tensor([47], device='cuda:0')], [tensor([27], device='cuda:0'), tensor([27], device='cuda:0'), tensor([29], device='cuda:0'), tensor([29], device='cuda:0')], [tensor([34], device='cuda:0'), tensor([34], device='cuda:0'), tensor([34], device='cuda:0'), tensor([34], device='cuda:0')], [tensor([43], device='cuda:0'), tensor([43], device='cuda:0'), tensor([45], device='cuda:0'), tensor([45], device='cuda:0')], [tensor([78], device='cuda:0'), tensor([78], device='cuda:0'), tensor([78], device='cuda:0'), tensor([78], device='cuda:0')], [tensor([12], device='cuda:0'), tensor([12], device='cuda:0'), tensor([25], device='cuda:0'), tensor([25], device='cuda:0')], [tensor([28], device='cuda:0'), tensor([28], device='cuda:0'), tensor([32], device='cuda:0'), tensor([32], device='cuda:0')], [tensor([18], device='cuda:0'), tensor([18], device='cuda:0'), tensor([22], device='cuda:0'), tensor([22], device='cuda:0')], [tensor([90], device='cuda:0'), tensor([90], device='cuda:0'), tensor([108], device='cuda:0'), tensor([108], device='cuda:0')], [tensor([223], device='cuda:0'), tensor([223], device='cuda:0'), tensor([224], device='cuda:0'), tensor([224], device='cuda:0')], [tensor([306], device='cuda:0'), tensor([306], device='cuda:0'), tensor([309], device='cuda:0'), tensor([309], device='cuda:0')], [tensor([292], device='cuda:0'), tensor([168], device='cuda:0'), tensor([185], device='cuda:0'), tensor([185], device='cuda:0')], [tensor([75], device='cuda:0'), tensor([75], device='cuda:0'), tensor([100], device='cuda:0'), tensor([100], device='cuda:0')], [tensor([14], device='cuda:0'), tensor([14], device='cuda:0'), tensor([16], device='cuda:0'), tensor([16], device='cuda:0')], [tensor([156], device='cuda:0'), tensor([156], device='cuda:0'), tensor([170], device='cuda:0'), tensor([170], device='cuda:0')], [tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([16], device='cuda:0')], [tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([29], device='cuda:0'), tensor([29], device='cuda:0')], [tensor([13], device='cuda:0'), tensor([13], device='cuda:0'), tensor([25], device='cuda:0'), tensor([25], device='cuda:0')], [tensor([20], device='cuda:0'), tensor([20], device='cuda:0'), tensor([24], device='cuda:0'), tensor([24], device='cuda:0')], [tensor([19], device='cuda:0'), tensor([19], device='cuda:0'), tensor([23], device='cuda:0'), tensor([23], device='cuda:0')], [tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([16], device='cuda:0')], [tensor([48], device='cuda:0'), tensor([48], device='cuda:0'), tensor([52], device='cuda:0'), tensor([52], device='cuda:0')], [tensor([246], device='cuda:0'), tensor([246], device='cuda:0'), tensor([248], device='cuda:0'), tensor([248], device='cuda:0')], [tensor([242], device='cuda:0'), tensor([242], device='cuda:0'), tensor([243], device='cuda:0'), tensor([243], device='cuda:0')], [tensor([209], device='cuda:0'), tensor([209], device='cuda:0'), tensor([216], device='cuda:0'), tensor([216], device='cuda:0')], [tensor([277], device='cuda:0'), tensor([277], device='cuda:0'), tensor([279], device='cuda:0'), tensor([279], device='cuda:0')], [tensor([31], device='cuda:0'), tensor([31], device='cuda:0'), tensor([31], device='cuda:0'), tensor([31], device='cuda:0')], [tensor([75], device='cuda:0'), tensor([75], device='cuda:0'), tensor([75], device='cuda:0'), tensor([75], device='cuda:0')], [tensor([66], device='cuda:0'), tensor([66], device='cuda:0'), tensor([71], device='cuda:0'), tensor([71], device='cuda:0')], [tensor([22], device='cuda:0'), tensor([22], device='cuda:0'), tensor([25], device='cuda:0'), tensor([25], device='cuda:0')], [tensor([266], device='cuda:0'), tensor([266], device='cuda:0'), tensor([267], device='cuda:0'), tensor([267], device='cuda:0')], [tensor([15], device='cuda:0'), tensor([15], device='cuda:0'), tensor([15], device='cuda:0'), tensor([15], device='cuda:0')], [tensor([17], device='cuda:0'), tensor([17], device='cuda:0'), tensor([22], device='cuda:0'), tensor([22], device='cuda:0')], [tensor([158], device='cuda:0'), tensor([158], device='cuda:0'), tensor([165], device='cuda:0'), tensor([165], device='cuda:0')], [tensor([14], device='cuda:0'), tensor([14], device='cuda:0'), tensor([15], device='cuda:0'), tensor([15], device='cuda:0')], [tensor([42], device='cuda:0'), tensor([42], device='cuda:0'), tensor([46], device='cuda:0'), tensor([46], device='cuda:0')], [tensor([134], device='cuda:0'), tensor([134], device='cuda:0'), tensor([158], device='cuda:0'), tensor([158], device='cuda:0')], [tensor([1], device='cuda:0'), tensor([1], device='cuda:0'), tensor([32], device='cuda:0'), tensor([32], device='cuda:0')], [tensor([71], device='cuda:0'), tensor([71], device='cuda:0'), tensor([77], device='cuda:0'), tensor([77], device='cuda:0')], [tensor([45], device='cuda:0'), tensor([45], device='cuda:0'), tensor([46], device='cuda:0'), tensor([46], device='cuda:0')], [tensor([133], device='cuda:0'), tensor([132], device='cuda:0'), tensor([149], device='cuda:0'), tensor([149], device='cuda:0')], [tensor([274], device='cuda:0'), tensor([274], device='cuda:0'), tensor([275], device='cuda:0'), tensor([275], device='cuda:0')], [tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([16], device='cuda:0')], [tensor([19], device='cuda:0'), tensor([19], device='cuda:0'), tensor([25], device='cuda:0'), tensor([25], device='cuda:0')], [tensor([20], device='cuda:0'), tensor([20], device='cuda:0'), tensor([24], device='cuda:0'), tensor([24], device='cuda:0')], [tensor([54], device='cuda:0'), tensor([54], device='cuda:0'), tensor([56], device='cuda:0'), tensor([56], device='cuda:0')], [tensor([78], device='cuda:0'), tensor([78], device='cuda:0'), tensor([86], device='cuda:0'), tensor([86], device='cuda:0')], [tensor([22], device='cuda:0'), tensor([22], device='cuda:0'), tensor([23], device='cuda:0'), tensor([23], device='cuda:0')], [tensor([343], device='cuda:0'), tensor([512], device='cuda:0'), tensor([409], device='cuda:0'), tensor([501], device='cuda:0')], [tensor([5], device='cuda:0'), tensor([5], device='cuda:0'), tensor([5], device='cuda:0'), tensor([5], device='cuda:0')], [tensor([34], device='cuda:0'), tensor([34], device='cuda:0'), tensor([41], device='cuda:0'), tensor([41], device='cuda:0')], [tensor([127], device='cuda:0'), tensor([127], device='cuda:0'), tensor([160], device='cuda:0'), tensor([160], device='cuda:0')], [tensor([96], device='cuda:0'), tensor([96], device='cuda:0'), tensor([99], device='cuda:0'), tensor([99], device='cuda:0')], [tensor([13], device='cuda:0'), tensor([13], device='cuda:0'), tensor([17], device='cuda:0'), tensor([17], device='cuda:0')], [tensor([9], device='cuda:0'), tensor([9], device='cuda:0'), tensor([11], device='cuda:0'), tensor([11], device='cuda:0')], [tensor([149], device='cuda:0'), tensor([149], device='cuda:0'), tensor([150], device='cuda:0'), tensor([150], device='cuda:0')], [tensor([292], device='cuda:0'), tensor([292], device='cuda:0'), tensor([296], device='cuda:0'), tensor([296], device='cuda:0')], [tensor([27], device='cuda:0'), tensor([27], device='cuda:0'), tensor([32], device='cuda:0'), tensor([32], device='cuda:0')], [tensor([176], device='cuda:0'), tensor([512], device='cuda:0'), tensor([183], device='cuda:0'), tensor([183], device='cuda:0')], [tensor([307], device='cuda:0'), tensor([307], device='cuda:0'), tensor([310], device='cuda:0'), tensor([310], device='cuda:0')], [tensor([39], device='cuda:0'), tensor([39], device='cuda:0'), tensor([41], device='cuda:0'), tensor([41], device='cuda:0')], [tensor([147], device='cuda:0'), tensor([147], device='cuda:0'), tensor([248], device='cuda:0'), tensor([248], device='cuda:0')], [tensor([118], device='cuda:0'), tensor([118], device='cuda:0'), tensor([120], device='cuda:0'), tensor([120], device='cuda:0')], [tensor([41], device='cuda:0'), tensor([41], device='cuda:0'), tensor([45], device='cuda:0'), tensor([45], device='cuda:0')], [tensor([75], device='cuda:0'), tensor([75], device='cuda:0'), tensor([75], device='cuda:0'), tensor([75], device='cuda:0')], [tensor([18], device='cuda:0'), tensor([18], device='cuda:0'), tensor([19], device='cuda:0'), tensor([19], device='cuda:0')], [tensor([26], device='cuda:0'), tensor([26], device='cuda:0'), tensor([26], device='cuda:0'), tensor([26], device='cuda:0')], [tensor([54], device='cuda:0'), tensor([54], device='cuda:0'), tensor([63], device='cuda:0'), tensor([63], device='cuda:0')], [tensor([53], device='cuda:0'), tensor([53], device='cuda:0'), tensor([65], device='cuda:0'), tensor([65], device='cuda:0')], [tensor([11], device='cuda:0'), tensor([11], device='cuda:0'), tensor([38], device='cuda:0'), tensor([38], device='cuda:0')], [tensor([19], device='cuda:0'), tensor([19], device='cuda:0'), tensor([19], device='cuda:0'), tensor([19], device='cuda:0')], [tensor([11], device='cuda:0'), tensor([11], device='cuda:0'), tensor([22], device='cuda:0'), tensor([22], device='cuda:0')], [tensor([230], device='cuda:0'), tensor([230], device='cuda:0'), tensor([250], device='cuda:0'), tensor([250], device='cuda:0')], [tensor([21], device='cuda:0'), tensor([21], device='cuda:0'), tensor([25], device='cuda:0'), tensor([25], device='cuda:0')], [tensor([14], device='cuda:0'), tensor([14], device='cuda:0'), tensor([15], device='cuda:0'), tensor([15], device='cuda:0')], [tensor([18], device='cuda:0'), tensor([18], device='cuda:0'), tensor([20], device='cuda:0'), tensor([20], device='cuda:0')], [tensor([354], device='cuda:0'), tensor([354], device='cuda:0'), tensor([356], device='cuda:0'), tensor([356], device='cuda:0')], [tensor([6], device='cuda:0'), tensor([6], device='cuda:0'), tensor([7], device='cuda:0'), tensor([7], device='cuda:0')], [tensor([6], device='cuda:0'), tensor([6], device='cuda:0'), tensor([22], device='cuda:0'), tensor([22], device='cuda:0')], [tensor([18], device='cuda:0'), tensor([18], device='cuda:0'), tensor([19], device='cuda:0'), tensor([19], device='cuda:0')], [tensor([18], device='cuda:0'), tensor([18], device='cuda:0'), tensor([22], device='cuda:0'), tensor([22], device='cuda:0')], [tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([19], device='cuda:0'), tensor([19], device='cuda:0')], [tensor([17], device='cuda:0'), tensor([17], device='cuda:0'), tensor([23], device='cuda:0'), tensor([23], device='cuda:0')], [tensor([13], device='cuda:0'), tensor([13], device='cuda:0'), tensor([17], device='cuda:0'), tensor([17], device='cuda:0')], [tensor([12], device='cuda:0'), tensor([12], device='cuda:0'), tensor([44], device='cuda:0'), tensor([42], device='cuda:0')], [tensor([90], device='cuda:0'), tensor([512], device='cuda:0'), tensor([365], device='cuda:0'), tensor([365], device='cuda:0')], [tensor([215], device='cuda:0'), tensor([215], device='cuda:0'), tensor([218], device='cuda:0'), tensor([218], device='cuda:0')], [tensor([27], device='cuda:0'), tensor([27], device='cuda:0'), tensor([29], device='cuda:0'), tensor([29], device='cuda:0')], [tensor([248], device='cuda:0'), tensor([248], device='cuda:0'), tensor([249], device='cuda:0'), tensor([249], device='cuda:0')], [tensor([19], device='cuda:0'), tensor([19], device='cuda:0'), tensor([19], device='cuda:0'), tensor([19], device='cuda:0')], [tensor([29], device='cuda:0'), tensor([29], device='cuda:0'), tensor([29], device='cuda:0'), tensor([29], device='cuda:0')], [tensor([14], device='cuda:0'), tensor([14], device='cuda:0'), tensor([17], device='cuda:0'), tensor([17], device='cuda:0')], [tensor([268], device='cuda:0'), tensor([268], device='cuda:0'), tensor([270], device='cuda:0'), tensor([270], device='cuda:0')], [tensor([1], device='cuda:0'), tensor([1], device='cuda:0'), tensor([47], device='cuda:0'), tensor([47], device='cuda:0')], [tensor([38], device='cuda:0'), tensor([38], device='cuda:0'), tensor([42], device='cuda:0'), tensor([42], device='cuda:0')], [tensor([71], device='cuda:0'), tensor([71], device='cuda:0'), tensor([80], device='cuda:0'), tensor([80], device='cuda:0')], [tensor([22], device='cuda:0'), tensor([22], device='cuda:0'), tensor([35], device='cuda:0'), tensor([35], device='cuda:0')], [tensor([185], device='cuda:0'), tensor([185], device='cuda:0'), tensor([186], device='cuda:0'), tensor([186], device='cuda:0')], [tensor([81], device='cuda:0'), tensor([81], device='cuda:0'), tensor([89], device='cuda:0'), tensor([89], device='cuda:0')], [tensor([37], device='cuda:0'), tensor([37], device='cuda:0'), tensor([38], device='cuda:0'), tensor([38], device='cuda:0')], [tensor([119], device='cuda:0'), tensor([119], device='cuda:0'), tensor([120], device='cuda:0'), tensor([120], device='cuda:0')], [tensor([10], device='cuda:0'), tensor([10], device='cuda:0'), tensor([31], device='cuda:0'), tensor([31], device='cuda:0')], [tensor([18], device='cuda:0'), tensor([18], device='cuda:0'), tensor([19], device='cuda:0'), tensor([19], device='cuda:0')], [tensor([292], device='cuda:0'), tensor([292], device='cuda:0'), tensor([296], device='cuda:0'), tensor([296], device='cuda:0')], [tensor([166], device='cuda:0'), tensor([166], device='cuda:0'), tensor([169], device='cuda:0'), tensor([169], device='cuda:0')], [tensor([32], device='cuda:0'), tensor([32], device='cuda:0'), tensor([43], device='cuda:0'), tensor([43], device='cuda:0')], [tensor([283], device='cuda:0'), tensor([283], device='cuda:0'), tensor([284], device='cuda:0'), tensor([284], device='cuda:0')], [tensor([155], device='cuda:0'), tensor([155], device='cuda:0'), tensor([156], device='cuda:0'), tensor([156], device='cuda:0')], [tensor([90], device='cuda:0'), tensor([512], device='cuda:0'), tensor([365], device='cuda:0'), tensor([437], device='cuda:0')], [tensor([50], device='cuda:0'), tensor([50], device='cuda:0'), tensor([58], device='cuda:0'), tensor([58], device='cuda:0')], [tensor([9], device='cuda:0'), tensor([9], device='cuda:0'), tensor([9], device='cuda:0'), tensor([9], device='cuda:0')], [tensor([46], device='cuda:0'), tensor([46], device='cuda:0'), tensor([47], device='cuda:0'), tensor([47], device='cuda:0')], [tensor([11], device='cuda:0'), tensor([11], device='cuda:0'), tensor([43], device='cuda:0'), tensor([43], device='cuda:0')], [tensor([2], device='cuda:0'), tensor([2], device='cuda:0'), tensor([13], device='cuda:0'), tensor([13], device='cuda:0')], [tensor([128], device='cuda:0'), tensor([128], device='cuda:0'), tensor([137], device='cuda:0'), tensor([137], device='cuda:0')], [tensor([48], device='cuda:0'), tensor([48], device='cuda:0'), tensor([49], device='cuda:0'), tensor([49], device='cuda:0')], [tensor([278], device='cuda:0'), tensor([278], device='cuda:0'), tensor([324], device='cuda:0'), tensor([324], device='cuda:0')], [tensor([1], device='cuda:0'), tensor([1], device='cuda:0'), tensor([4], device='cuda:0'), tensor([4], device='cuda:0')], [tensor([43], device='cuda:0'), tensor([43], device='cuda:0'), tensor([46], device='cuda:0'), tensor([46], device='cuda:0')], [tensor([28], device='cuda:0'), tensor([28], device='cuda:0'), tensor([31], device='cuda:0'), tensor([31], device='cuda:0')], [tensor([17], device='cuda:0'), tensor([17], device='cuda:0'), tensor([18], device='cuda:0'), tensor([18], device='cuda:0')], [tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([16], device='cuda:0'), tensor([16], device='cuda:0')], [tensor([386], device='cuda:0'), tensor([386], device='cuda:0'), tensor([402], device='cuda:0'), tensor([402], device='cuda:0')], [tensor([17], device='cuda:0'), tensor([17], device='cuda:0'), tensor([21], device='cuda:0'), tensor([21], device='cuda:0')], [tensor([24], device='cuda:0'), tensor([24], device='cuda:0'), tensor([31], device='cuda:0'), tensor([31], device='cuda:0')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_eval(eval_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "C7cnbRnSuESi",
        "outputId": "8cc30c10-0052-4c38-dfe5-02fa15e4483d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x576 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pi51WAAW_ZCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}