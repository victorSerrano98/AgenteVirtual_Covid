{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUwPe39SB_Rp",
        "outputId": "ddeacfd4-94bb-4c99-8a88-f03d7dcda7ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: torchvision==0.10.0 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: torchaudio==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: torchtext==0.10.0 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.10.0.2)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.62.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2021.10.8)\n",
            "Requirement already satisfied: transformers==4.8.0 in /usr/local/lib/python3.7/dist-packages (4.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (1.21.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (3.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.11.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (0.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (0.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (0.0.47)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.8.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.8.0) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.8.0) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (7.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 torchtext==0.10.0\n",
        "#!pip uninstall transformers -y\n",
        "!pip install transformers==4.8.0\n",
        "!pip install transformers sentencepiece\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ3lrB9WBbJ-",
        "outputId": "f4ab93c0-2ae0-4b3c-9844-5541e08aecc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch, time, gc\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCYepNomOQxR",
        "outputId": "92649313-ceb4-4964-96df-c567215003ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar  1 21:49:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    26W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGCFFRKMHui2",
        "outputId": "d7bd38f8-8820-4a1e-fd3c-d1a6596854f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiFVXS-NECVR"
      },
      "outputs": [],
      "source": [
        "def read_squad(path):\n",
        "    # se abre el archivo JSON y cargue el diccionario de introducción\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    # inicializar listas para contextos, preguntas y respuestas // título, pregunta, respuesta, resumen (contextos)\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    # itera a través de todos los datos \n",
        "\n",
        "    for i in squad_dict:\n",
        "        try:\n",
        "            context = i['context']\n",
        "            question = i['question']\n",
        "            answer = i['answer']\n",
        "            # comprueba si necesitamos extraer de 'answers' o 'plausible_answers'\n",
        "            if 'plausible_answers' in i.keys():\n",
        "                access = 'plausible_answers'\n",
        "            else:\n",
        "                access = 'answers'\n",
        "            # agregar datos a listas // título, pregunta, respuesta, resumen\n",
        "            contexts.append(context)\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "        except:\n",
        "            print(\"eeee\")\n",
        "    # devolver listas de datos \n",
        "    return contexts, questions, answers\n",
        "\n",
        "# se ejecuta la función de lectura SQuAD para conjuntos de entrenamiento y validación\n",
        "train_contexts, train_questions, train_answers = read_squad('/content/drive/MyDrive/Colab Notebooks/ajusteBert/datosunido.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('/content/drive/MyDrive/Colab Notebooks/ajusteBert/datosCopy.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVxASePjEI8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdae9d67-d010-4455-90da-6c42943e092e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " March 2020, the World Health Organization (WHO) declared COVID-19 a global pandemic. Since then, the rate of infections around the world has increase\n",
            "what is covid-19?\n",
            "{'text': 'a global pandemic', 'answer_start': 67}\n",
            "a global pandemic\n",
            "global pandemic\n",
            "an infected person transmits the virus to many more people than average\n",
            "identifying other infected people\n",
            "airborne transmission\n",
            "wear a mask in public, maintain social distancing of at least six feet\n",
            "face mask/covering when outside\n",
            "talking to my friends about hand washing, face masks, etc\n",
            "Skin-to-skin contact was not recommended in women with symptoms, regardless of the severity of the illness; early clamping of the cord was promoted; and breastfeeding was not recommended for COVID-19+ mothers\n",
            "Skin-to-skin contact was not recommended in women with symptoms, regardless of the severity of the illness\n",
            "recommending the presence of a companion during birth with the adequate personal protective equipment (PPE), skin-to-skin contact after birth and breastfeeding\n",
            "fatigue, myalgias-arthralgias, and neurological (i.e., headaches, “brain fog”),\n",
            "ranging from mild symptoms to symptoms of acute respiratory distress syndrome\n",
            "fatigue, myalgias-arthralgias, and neurological (i.e., headaches, “brain fog”\n",
            "anyone who tested positive through real-time RT-PCR\n",
            "RBD, class B CpG ODN1826 (CpG), and Alhydrogel (Alum\n",
            "14 days\n",
            "BNT162b2 and mRNA-1273\n",
            "BNT162b2\n",
            "Pfizer-BioNTech\n",
            "mRNA\n",
            "BNT162b2\n",
            "Pfizer-BioNTech and Moderna\n",
            "ChAdOx1\n",
            "Ad26.COV2.S\n",
            "SARS-CoV-2 and COVID-19\n",
            "1 month\n",
            "BNT162b2 and ChAdOx1 nCoV-19\n",
            " the effectiveness of two doses was 93.7%\n",
            " the effectiveness of two doses was 74.5%\n",
            "12 days\n",
            "21-day\n",
            "1 month\n",
            "2 weeks\n",
            "12 days\n",
            "3–4 days\n",
            "11 to 31 days\n",
            "30 days\n",
            "2 months\n",
            "2 weeks\n",
            "11 days\n",
            "3 weeks\n",
            "3 weeks\n",
            "21 days\n",
            "7 days\n",
            "19 days\n",
            "1-3 weeks\n",
            "Two weeks\n",
            "7 days\n",
            "1–3 weeks\n",
            "14 days\n",
            "3-week\n",
            "Wuhan, China\n",
            "COVID-19\n",
            "Wuhan, China\n",
            "around the world\n",
            "Wuhan, China\n",
            "benign\n",
            "China\n",
            "China\n",
            "China\n",
            "Wuhan, China\n",
            "Wuhan, China\n",
            "Wuhan, China\n",
            "Indonesia\n",
            "China\n",
            "Wuhan, China\n",
            "China\n",
            "China\n",
            "Wuhan, China\n",
            "Wuhan\n",
            "Wuhan\n",
            "China\n",
            "China\n",
            "Turkey\n",
            "Pakistan\n",
            "China\n",
            "China\n",
            "Turkey\n",
            "China\n",
            "China\n",
            "China\n",
            "Wuhan, China\n",
            "patients with atypical presentations\n",
            "Amazon Mechanical Turk\n",
            "Wuhan, China\n",
            "China\n",
            "China\n",
            "China\n",
            "Wuhan, China\n",
            "China\n",
            "cough, shortness of breath, and fever\n",
            "acute respiratory failure and systemic coagulopathy\n",
            "diarrhea, nausea, and vomiting\n",
            "complications\n",
            "anxiety and depression\n",
            "fever, fatigue, and a dry cough\n",
            "fever, fatigue, and a dry cough\n",
            "tissue damage and a cytokine storm\n",
            "anosmia\n",
            "person-to-person\n",
            "through ocular surface\n",
            "by asymptomatic individuals\n",
            "Use of medical masks\n",
            "personal protective measures\n",
            "Good preparedness measures\n",
            "Wearing masks\n",
            "via the eyes\n",
            "anosmia, ageusia, difficulty concentrating, dyspnea, memory loss, confusion, headache, heart palpitations, chest pain, pain with deep breaths, dizziness, and tachycardia\n",
            "fatigue and breathlessness\n",
            "affect different body systems: immune system (including but not limited to Guillain-Barré syndrome and paediatric inflammatory multisystem syndrome), respiratory system (lung fibrosis and pulmonary thromboembolism), cardiovascular system (cardiomyopathy and coagulopathy), neurological system (sensory dysfunction and stroke), as well as cutaneous and gastrointestinal manifestations, impaired hepatic and renal function.\n",
            "antibody tests\n",
            "The antibody tests for SARS-CoV-2 detect the presence of IgA, IgM, or IgG antibodies produced by B cells\n",
            "immunochromatographic serological test kits\n",
            "antibody tests\n",
            "Antibody Rapid Test Kit\n",
            "RT-PCR testing method\n",
            "is a betacoronavirus belonging to the subgenus Sarbecovirus\n",
            "enveloped, positive single‐stranded large RNA viruses that infect humans\n",
            "age, C-reactive protein, D-dimer, albumin, body temperature, SOFA score and diabetes\n",
            " age is the variable that presents higher risk\n",
            "Older age, cardiovascular disease, diabetes, chronic respiratory disease, hypertension, and cancer \n",
            "diabetes, obesity, cancer, respiratory diseases, heart, kidney, liver, neurological and autoimmune conditions\n",
            "poor state of health such as high age, obesity, diabetes and hypertension\n",
            "nucleic acid, serological, antigen, and ancillary tests\n",
            "BNT162b2 and mRNA-1273\n",
            "BNT162b2\n",
            "Pfizer-BioNTech\n",
            "mRNA\n",
            "BNT162b2\n",
            "Pfizer-BioNTech and Moderna\n",
            "ChAdOx1\n",
            "Ad26.COV2.S\n",
            "SARS-CoV-2 and COVID-19\n",
            "1 month\n",
            "BNT162b2 and ChAdOx1 nCoV-19\n",
            " the effectiveness of two doses was 93.7%\n",
            " the effectiveness of two doses was 74.5%\n",
            "12 days\n",
            "21-day\n",
            "1 month\n",
            "2 weeks\n",
            "12 days\n",
            "3–4 days\n",
            "11 to 31 days\n",
            "30 days\n",
            "2 months\n",
            "2 weeks\n",
            "11 days\n",
            "3 weeks\n",
            "3 weeks\n",
            "21 days\n",
            "7 days\n",
            "19 days\n",
            "1-3 weeks\n",
            "Two weeks\n",
            "7 days\n",
            "1–3 weeks\n",
            "14 days\n",
            "3-week\n",
            "Wuhan, China\n",
            "COVID-19\n",
            "Wuhan, China\n",
            "around the world\n",
            "Wuhan, China\n",
            "benign\n",
            "China\n",
            "China\n",
            "China\n",
            "Wuhan, China\n",
            "Wuhan, China\n",
            "Wuhan, China\n",
            "Indonesia\n",
            "China\n",
            "Wuhan, China\n",
            "China\n",
            "China\n",
            "Wuhan, China\n",
            "Wuhan\n",
            "Wuhan\n",
            "China\n",
            "China\n",
            "Turkey\n",
            "Pakistan\n",
            "China\n",
            "China\n",
            "Turkey\n",
            "China\n",
            "China\n",
            "China\n",
            "Wuhan, China\n",
            "patients with atypical presentations\n",
            "Amazon Mechanical Turk\n",
            "Wuhan, China\n",
            "China\n",
            "China\n",
            "China\n",
            "Wuhan, China\n",
            "China\n",
            "cough, shortness of breath, and fever\n",
            "acute respiratory failure and systemic coagulopathy\n",
            "diarrhea, nausea, and vomiting\n",
            "complications\n",
            "anxiety and depression\n",
            "fever, fatigue, and a dry cough\n",
            "fever, fatigue, and a dry cough\n",
            "tissue damage and a cytokine storm\n",
            "anosmia\n",
            "person-to-person\n",
            "through ocular surface\n",
            "by asymptomatic individuals\n",
            "Use of medical masks\n",
            "personal protective measures\n",
            "Good preparedness measures\n",
            "Wearing masks\n",
            "via the eyes\n",
            "anosmia, ageusia, difficulty concentrating, dyspnea, memory loss, confusion, headache, heart palpitations, chest pain, pain with deep breaths, dizziness, and tachycardia\n",
            "fatigue and breathlessness\n",
            "affect different body systems: immune system (including but not limited to Guillain-Barré syndrome and paediatric inflammatory multisystem syndrome), respiratory system (lung fibrosis and pulmonary thromboembolism), cardiovascular system (cardiomyopathy and coagulopathy), neurological system (sensory dysfunction and stroke), as well as cutaneous and gastrointestinal manifestations, impaired hepatic and renal function.\n",
            "antibody tests\n",
            "The antibody tests for SARS-CoV-2 detect the presence of IgA, IgM, or IgG antibodies produced by B cells\n",
            "immunochromatographic serological test kits\n",
            "antibody tests\n",
            "Antibody Rapid Test Kit\n",
            "RT-PCR testing method\n",
            "is a betacoronavirus belonging to the subgenus Sarbecovirus\n",
            "enveloped, positive single‐stranded large RNA viruses that infect humans\n",
            "age, C-reactive protein, D-dimer, albumin, body temperature, SOFA score and diabetes\n",
            " age is the variable that presents higher risk\n",
            "Older age, cardiovascular disease, diabetes, chronic respiratory disease, hypertension, and cancer \n",
            "diabetes, obesity, cancer, respiratory diseases, heart, kidney, liver, neurological and autoimmune conditions\n",
            "poor state of health such as high age, obesity, diabetes and hypertension\n",
            "nucleic acid, serological, antigen, and ancillary tests\n"
          ]
        }
      ],
      "source": [
        "print(train_contexts[0])\n",
        "print(train_questions[0])\n",
        "print(train_answers[0])\n",
        "\n",
        "def add_end_idx(answers, contexts):\n",
        "    # se recorre cada par respuesta-contexto\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        # gold_text se refiere a la respuesta que esperamos encontrar en contexto\n",
        "        print(answer['text'])\n",
        "        gold_text = answer['text']\n",
        "        # se conoce el índice de inicio\n",
        "        start_idx = answer['answer_start']\n",
        "        # idealmente este sería el índice final\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # A veces las respuestas se desvían por un personaje o dos\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            # si la respuesta no es apagada\n",
        "            answer['answer_end'] = end_idx\n",
        "        else:\n",
        "            # esto significa que la respuesta está desviada por 1-2 tokens\n",
        "            for n in [1, 2]:\n",
        "                if context[start_idx - n:end_idx - n] == gold_text:\n",
        "                    answer['answer_start'] = start_idx - n\n",
        "                    answer['answer_end'] = end_idx - n\n",
        "\n",
        "\n",
        "# y se aplica la función a nuestras dos listas de respuestas\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iVwfDJ1D47m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f023fc60-650c-4db9-f5a9-0c450387800f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': 'a global pandemic', 'answer_start': 67, 'answer_end': 84}, {'text': 'global pandemic', 'answer_start': 68, 'answer_end': 83}, {'text': 'an infected person transmits the virus to many more people than average', 'answer_start': 40, 'answer_end': 111}, {'text': 'identifying other infected people', 'answer_start': 59, 'answer_end': 92}, {'text': 'airborne transmission', 'answer_start': 65, 'answer_end': 86}]\n",
            "[CLS] March 2020, the World Health Organization ( WHO ) declared COVID - 19 a global pandemic. Since then, the rate of infections around the world has increase [SEP] what is covid - 19? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "67\n",
            "a global pandemic\n",
            "68\n",
            "global pandemic\n",
            "40\n",
            "an infected person transmits the virus to many more people than average\n",
            "59\n",
            "identifying other infected people\n",
            "65\n",
            "airborne transmission\n",
            "40\n",
            "wear a mask in public, maintain social distancing of at least six feet\n",
            "60\n",
            "face mask/covering when outside\n",
            "47\n",
            "talking to my friends about hand washing, face masks, etc\n",
            "0\n",
            "Skin-to-skin contact was not recommended in women with symptoms, regardless of the severity of the illness; early clamping of the cord was promoted; and breastfeeding was not recommended for COVID-19+ mothers\n",
            "22\n",
            "Skin-to-skin contact was not recommended in women with symptoms, regardless of the severity of the illness\n",
            "1\n",
            "recommending the presence of a companion during birth with the adequate personal protective equipment (PPE), skin-to-skin contact after birth and breastfeeding\n",
            "36\n",
            "fatigue, myalgias-arthralgias, and neurological (i.e., headaches, “brain fog”),\n",
            "37\n",
            "ranging from mild symptoms to symptoms of acute respiratory distress syndrome\n",
            "37\n",
            "fatigue, myalgias-arthralgias, and neurological (i.e., headaches, “brain fog”\n",
            "50\n",
            "anyone who tested positive through real-time RT-PCR\n",
            "49\n",
            "RBD, class B CpG ODN1826 (CpG), and Alhydrogel (Alum\n",
            "72\n",
            "14 days\n",
            "249\n",
            "BNT162b2 and mRNA-1273\n",
            "99\n",
            "BNT162b2\n",
            "146\n",
            "Pfizer-BioNTech\n",
            "69\n",
            "mRNA\n",
            "280\n",
            "BNT162b2\n",
            "94\n",
            "Pfizer-BioNTech and Moderna\n",
            "293\n",
            "ChAdOx1\n",
            "75\n",
            "Ad26.COV2.S\n",
            "127\n",
            "SARS-CoV-2 and COVID-19\n",
            "579\n",
            "1 month\n",
            "344\n",
            "BNT162b2 and ChAdOx1 nCoV-19\n",
            "1287\n",
            " the effectiveness of two doses was 93.7%\n",
            "1491\n",
            " the effectiveness of two doses was 74.5%\n",
            "776\n",
            "12 days\n",
            "1000\n",
            "21-day\n",
            "392\n",
            "1 month\n",
            "130\n",
            "2 weeks\n",
            "237\n",
            "12 days\n",
            "1420\n",
            "3–4 days\n",
            "154\n",
            "11 to 31 days\n",
            "981\n",
            "30 days\n",
            "846\n",
            "2 months\n",
            "1035\n",
            "2 weeks\n",
            "202\n",
            "11 days\n",
            "204\n",
            "3 weeks\n",
            "850\n",
            "3 weeks\n",
            "545\n",
            "21 days\n",
            "1013\n",
            "7 days\n",
            "1276\n",
            "19 days\n",
            "1133\n",
            "1-3 weeks\n",
            "1102\n",
            "Two weeks\n",
            "178\n",
            "7 days\n",
            "1133\n",
            "1–3 weeks\n",
            "222\n",
            "14 days\n",
            "160\n",
            "3-week\n",
            "63\n",
            "Wuhan, China\n",
            "101\n",
            "COVID-19\n",
            "52\n",
            "Wuhan, China\n",
            "741\n",
            "around the world\n",
            "93\n",
            "Wuhan, China\n",
            "837\n",
            "benign\n",
            "64\n",
            "China\n",
            "70\n",
            "China\n",
            "70\n",
            "China\n",
            "54\n",
            "Wuhan, China\n",
            "159\n",
            "Wuhan, China\n",
            "54\n",
            "Wuhan, China\n",
            "108\n",
            "Indonesia\n",
            "67\n",
            "China\n",
            "65\n",
            "Wuhan, China\n",
            "111\n",
            "China\n",
            "111\n",
            "China\n",
            "65\n",
            "Wuhan, China\n",
            "110\n",
            "Wuhan\n",
            "110\n",
            "Wuhan\n",
            "67\n",
            "China\n",
            "23\n",
            "China\n",
            "346\n",
            "Turkey\n",
            "63\n",
            "Pakistan\n",
            "30\n",
            "China\n",
            "33\n",
            "China\n",
            "346\n",
            "Turkey\n",
            "85\n",
            "China\n",
            "30\n",
            "China\n",
            "32\n",
            "China\n",
            "117\n",
            "Wuhan, China\n",
            "60\n",
            "patients with atypical presentations\n",
            "451\n",
            "Amazon Mechanical Turk\n",
            "117\n",
            "Wuhan, China\n",
            "109\n",
            "China\n",
            "68\n",
            "China\n",
            "68\n",
            "China\n",
            "83\n",
            "Wuhan, China\n",
            "40\n",
            "China\n",
            "267\n",
            "cough, shortness of breath, and fever\n",
            "263\n",
            "acute respiratory failure and systemic coagulopathy\n",
            "235\n",
            "diarrhea, nausea, and vomiting\n",
            "326\n",
            "complications\n",
            "70\n",
            "anxiety and depression\n",
            "368\n",
            "fever, fatigue, and a dry cough\n",
            "359\n",
            "fever, fatigue, and a dry cough\n",
            "548\n",
            "tissue damage and a cytokine storm\n",
            "158\n",
            "anosmia\n",
            "196\n",
            "person-to-person\n",
            "164\n",
            "through ocular surface\n",
            "847\n",
            "by asymptomatic individuals\n",
            "0\n",
            "Use of medical masks\n",
            "41\n",
            "personal protective measures\n",
            "967\n",
            "Good preparedness measures\n",
            "1186\n",
            "Wearing masks\n",
            "2481\n",
            "via the eyes\n",
            "1076\n",
            "anosmia, ageusia, difficulty concentrating, dyspnea, memory loss, confusion, headache, heart palpitations, chest pain, pain with deep breaths, dizziness, and tachycardia\n",
            "178\n",
            "fatigue and breathlessness\n",
            "669\n",
            "affect different body systems: immune system (including but not limited to Guillain-Barré syndrome and paediatric inflammatory multisystem syndrome), respiratory system (lung fibrosis and pulmonary thromboembolism), cardiovascular system (cardiomyopathy and coagulopathy), neurological system (sensory dysfunction and stroke), as well as cutaneous and gastrointestinal manifestations, impaired hepatic and renal function.\n",
            "564\n",
            "antibody tests\n",
            "561\n",
            "The antibody tests for SARS-CoV-2 detect the presence of IgA, IgM, or IgG antibodies produced by B cells\n",
            "8\n",
            "immunochromatographic serological test kits\n",
            "76\n",
            "antibody tests\n",
            "1225\n",
            "Antibody Rapid Test Kit\n",
            "978\n",
            "RT-PCR testing method\n",
            "515\n",
            "is a betacoronavirus belonging to the subgenus Sarbecovirus\n",
            "726\n",
            "enveloped, positive single‐stranded large RNA viruses that infect humans\n",
            "693\n",
            "age, C-reactive protein, D-dimer, albumin, body temperature, SOFA score and diabetes\n",
            "845\n",
            " age is the variable that presents higher risk\n",
            "943\n",
            "Older age, cardiovascular disease, diabetes, chronic respiratory disease, hypertension, and cancer \n",
            "373\n",
            "diabetes, obesity, cancer, respiratory diseases, heart, kidney, liver, neurological and autoimmune conditions\n",
            "870\n",
            "poor state of health such as high age, obesity, diabetes and hypertension\n",
            "1637\n",
            "nucleic acid, serological, antigen, and ancillary tests\n",
            "249\n",
            "BNT162b2 and mRNA-1273\n",
            "99\n",
            "BNT162b2\n",
            "146\n",
            "Pfizer-BioNTech\n",
            "69\n",
            "mRNA\n",
            "280\n",
            "BNT162b2\n",
            "94\n",
            "Pfizer-BioNTech and Moderna\n",
            "293\n",
            "ChAdOx1\n",
            "75\n",
            "Ad26.COV2.S\n",
            "127\n",
            "SARS-CoV-2 and COVID-19\n",
            "579\n",
            "1 month\n",
            "344\n",
            "BNT162b2 and ChAdOx1 nCoV-19\n",
            "1287\n",
            " the effectiveness of two doses was 93.7%\n",
            "1491\n",
            " the effectiveness of two doses was 74.5%\n",
            "776\n",
            "12 days\n",
            "1000\n",
            "21-day\n",
            "392\n",
            "1 month\n",
            "130\n",
            "2 weeks\n",
            "237\n",
            "12 days\n",
            "1420\n",
            "3–4 days\n",
            "154\n",
            "11 to 31 days\n",
            "981\n",
            "30 days\n",
            "846\n",
            "2 months\n",
            "1035\n",
            "2 weeks\n",
            "202\n",
            "11 days\n",
            "204\n",
            "3 weeks\n",
            "850\n",
            "3 weeks\n",
            "545\n",
            "21 days\n",
            "1013\n",
            "7 days\n",
            "1276\n",
            "19 days\n",
            "1133\n",
            "1-3 weeks\n",
            "1102\n",
            "Two weeks\n",
            "178\n",
            "7 days\n",
            "1133\n",
            "1–3 weeks\n",
            "222\n",
            "14 days\n",
            "160\n",
            "3-week\n",
            "63\n",
            "Wuhan, China\n",
            "101\n",
            "COVID-19\n",
            "52\n",
            "Wuhan, China\n",
            "741\n",
            "around the world\n",
            "93\n",
            "Wuhan, China\n",
            "837\n",
            "benign\n",
            "64\n",
            "China\n",
            "70\n",
            "China\n",
            "70\n",
            "China\n",
            "54\n",
            "Wuhan, China\n",
            "159\n",
            "Wuhan, China\n",
            "54\n",
            "Wuhan, China\n",
            "108\n",
            "Indonesia\n",
            "67\n",
            "China\n",
            "65\n",
            "Wuhan, China\n",
            "111\n",
            "China\n",
            "111\n",
            "China\n",
            "65\n",
            "Wuhan, China\n",
            "110\n",
            "Wuhan\n",
            "110\n",
            "Wuhan\n",
            "67\n",
            "China\n",
            "23\n",
            "China\n",
            "346\n",
            "Turkey\n",
            "63\n",
            "Pakistan\n",
            "30\n",
            "China\n",
            "33\n",
            "China\n",
            "346\n",
            "Turkey\n",
            "85\n",
            "China\n",
            "30\n",
            "China\n",
            "32\n",
            "China\n",
            "117\n",
            "Wuhan, China\n",
            "60\n",
            "patients with atypical presentations\n",
            "451\n",
            "Amazon Mechanical Turk\n",
            "117\n",
            "Wuhan, China\n",
            "109\n",
            "China\n",
            "68\n",
            "China\n",
            "68\n",
            "China\n",
            "83\n",
            "Wuhan, China\n",
            "40\n",
            "China\n",
            "267\n",
            "cough, shortness of breath, and fever\n",
            "263\n",
            "acute respiratory failure and systemic coagulopathy\n",
            "235\n",
            "diarrhea, nausea, and vomiting\n",
            "326\n",
            "complications\n",
            "70\n",
            "anxiety and depression\n",
            "368\n",
            "fever, fatigue, and a dry cough\n",
            "359\n",
            "fever, fatigue, and a dry cough\n",
            "548\n",
            "tissue damage and a cytokine storm\n",
            "158\n",
            "anosmia\n",
            "196\n",
            "person-to-person\n",
            "164\n",
            "through ocular surface\n",
            "847\n",
            "by asymptomatic individuals\n",
            "0\n",
            "Use of medical masks\n",
            "41\n",
            "personal protective measures\n",
            "967\n",
            "Good preparedness measures\n",
            "1186\n",
            "Wearing masks\n",
            "2481\n",
            "via the eyes\n",
            "1076\n",
            "anosmia, ageusia, difficulty concentrating, dyspnea, memory loss, confusion, headache, heart palpitations, chest pain, pain with deep breaths, dizziness, and tachycardia\n",
            "178\n",
            "fatigue and breathlessness\n",
            "669\n",
            "affect different body systems: immune system (including but not limited to Guillain-Barré syndrome and paediatric inflammatory multisystem syndrome), respiratory system (lung fibrosis and pulmonary thromboembolism), cardiovascular system (cardiomyopathy and coagulopathy), neurological system (sensory dysfunction and stroke), as well as cutaneous and gastrointestinal manifestations, impaired hepatic and renal function.\n",
            "564\n",
            "antibody tests\n",
            "561\n",
            "The antibody tests for SARS-CoV-2 detect the presence of IgA, IgM, or IgG antibodies produced by B cells\n",
            "8\n",
            "immunochromatographic serological test kits\n",
            "76\n",
            "antibody tests\n",
            "1225\n",
            "Antibody Rapid Test Kit\n",
            "978\n",
            "RT-PCR testing method\n",
            "515\n",
            "is a betacoronavirus belonging to the subgenus Sarbecovirus\n",
            "726\n",
            "enveloped, positive single‐stranded large RNA viruses that infect humans\n",
            "693\n",
            "age, C-reactive protein, D-dimer, albumin, body temperature, SOFA score and diabetes\n",
            "845\n",
            " age is the variable that presents higher risk\n",
            "943\n",
            "Older age, cardiovascular disease, diabetes, chronic respiratory disease, hypertension, and cancer \n",
            "373\n",
            "diabetes, obesity, cancer, respiratory diseases, heart, kidney, liver, neurological and autoimmune conditions\n",
            "870\n",
            "poor state of health such as high age, obesity, diabetes and hypertension\n",
            "1637\n",
            "nucleic acid, serological, antigen, and ancillary tests\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(train_answers[:5])\n",
        "from transformers import AutoTokenizer\n",
        "# inicializar el tokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
        "# tokenizador\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)\n",
        "print(tokenizer.decode(train_encodings['input_ids'][0]))\n",
        "\n",
        "def add_token_positions(encodings, answers):\n",
        "    # se inicializa las listas para contener los índices de token de inicio / final de respuesta\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i in range(len(answers)):\n",
        "        print(answers[i]['answer_start'])\n",
        "        print(answers[i]['text'])\n",
        "        # agregar la posición del token de inicio / finalización usando el método char_to_token\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
        "        # si la posición inicial es None, el pasaje de respuesta se ha truncado\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        # la posición final no se puede encontrar, char_to_token encontró el espacio, así que cambie la posición hasta encontrarla\n",
        "        shift = 1\n",
        "        while end_positions[-1] is None:\n",
        "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n",
        "            shift += 1\n",
        "    # Actualiza nuestro objeto de codificaciones con las nuevas posiciones de inicio / finalización basadas en tokens.\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "# Se aplica la funcion a los datos\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "metadata": {
        "id": "ffEdF97DEwLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTp5wjmtEU1E"
      },
      "outputs": [],
      "source": [
        "#Entrenamiento\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "model_path = \"deepset/bert-base-cased-squad2\"\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "# configurar GPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# se mueve el modelo al dispositivo detectado\n",
        "model.to(device)\n",
        "# se activa el modo de entrenamiento del modelo\n",
        "model.train()\n",
        "# se inicializa adam optimizer con caída de peso (reduce la posibilidad de sobreajuste)\n",
        "optim = AdamW(model.parameters(), lr=2e-5) #tasa de aprendizaje\n",
        "# Se inicializa el cargador de datos para los datos de entrenamiento\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "for epoch in range(7):\n",
        "    # configurar el modelo en modo de entrenamiento\n",
        "    model.train()\n",
        "    # bucle de configuración (usamos tqdm para la barra de progreso)\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        # Se inicializa los gradientes calculados (del paso anterior)\n",
        "        optim.zero_grad()\n",
        "        # extraer todos los lotes de tensores necesarios para el entrenamiento\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        # Salida del modelo de entrenamiento por lotes y devoluciones (incluida la pérdida)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                        start_positions=start_positions,\n",
        "                        end_positions=end_positions)\n",
        "        # extraer la pérdida\n",
        "        loss = outputs[0]\n",
        "        # calcula la pérdida para cada parámetro que necesite actualización gradual\n",
        "        loss.backward()\n",
        "        # actualiza los parámetros\n",
        "        optim.step()\n",
        "        # imprime información relevante en la barra de progreso\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "# GUARDAR EL MODELO AJUSTADO\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/ajusteBert/tokenizerv3\")\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/ajusteBert/modelv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKFhRbkHDYUa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline, QuestionAnsweringPipeline\n",
        "\n",
        "## CARGAR EL MODELO\n",
        "# Cargarmos el modelo usando \"AutoModel\" or BertModel:\n",
        "loaded_model = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/ajusteBert/model\")\n",
        "load_tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/ajusteBert/tokenizer\")\n",
        "#BertModel.from_pretrained(\"C:/Users/Alexis/PycharmProjects/ModeloBERT/model/FineTune_BERT.pt\")\n",
        "\n",
        "# Question answering pipeline, specifying the checkpoint identifier\n",
        "# Canal de respuesta a preguntas \"pipeline\", especificando el modelo cargado\n",
        "question_answerer = QuestionAnsweringPipeline(model=loaded_model, tokenizer=load_tokenizer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN56S7Kwtjqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eab0f91-9758-4397-b06c-86ed7dd25961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 2.6897090720012784e-05, 'start': 373, 'end': 399, 'answer': 'diabetes, obesity, cancer,'}\n",
            "Answer: 'diabetes, obesity, cancer,', score: 0.0, start: 373, end: 399\n"
          ]
        }
      ],
      "source": [
        "questions = \"Covid-19 risk factors?\"\n",
        "contexto = \"To identify risk factors for hospital deaths from COVID-19, the OpenSAFELY platform examined electronic health records from 17.4 million UK adults. The authors used multivariable Cox proportional hazards model to identify the association of risk of death with older age, lower socio-economic status, being male, non-white ethnic background and certain clinical conditions (diabetes, obesity, cancer, respiratory diseases, heart, kidney, liver, neurological and autoimmune conditions). Notably, asthma was identified as a risk factor, despite prior suggestion of a potential protective role. Interestingly, higher risks due to ethnicity or lower socio-economic status could not be completely attributed to pre-existing health conditions.\"\n",
        "result = question_answerer(question=questions, context=contexto)\n",
        "print(result)\n",
        "# texto=client['resumen']\n",
        "# ocurrencias = texto.count(palabra)\n",
        "# print(ocurrencias)\n",
        "#x = (round(result['score'], 4))\n",
        "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4JfDmxioMDC",
        "outputId": "e259bbaa-6b5d-4316-e550-73a2f146920d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='deepset/bert-base-cased-squad2', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xI25b4XhoLpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.base_model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-nSuOp0o-C_",
        "outputId": "a3aa4a76-f546-436f-a338-51afcd90bf0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"deepset/bert-base-cased-squad2\",\n",
              "  \"architectures\": [\n",
              "    \"BertForQuestionAnswering\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"language\": \"english\",\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"name\": \"Bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.8.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 28996\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WNGjAg1bpCxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copia de ajuste_bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}